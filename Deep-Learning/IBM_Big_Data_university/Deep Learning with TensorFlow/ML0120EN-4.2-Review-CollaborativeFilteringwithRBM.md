
<a href="https://www.bigdatauniversity.com"><img src = "https://ibm.box.com/shared/static/wbqvbi6o6ip0vz55ua5gp17g4f1k7ve9.png" width = 300, align = "center"></a>

<h1 align=center><font size = 5>RECOMMENDATION SYSTEM WITH A RESTRICTED BOLTZMANN MACHINE</font></h1>

Welcome to the **Recommendation System with a Restricted Boltzmann Machine** notebook. In this notebook, we study and go over the usage of a Restricted Boltzmann Machine (RBM) in a Collaborative Filtering based recommendation system. This system is an algorithm that recommends items by trying to find users that are similar to each other based on their item ratings. By the end of this notebook, you should have a deeper understanding of how Restricted Boltzmann Machines are applied, and how to build one using TensorFlow.

### Table of contents

<div class="alert alert-block alert-info" style="margin-top: 20px">
- <p><a href="#ref1">Acquiring the Data</a></p>
- <p><a href="#ref2">Loading in the Data</a></p>
- <p><a href="#ref3">The Restricted Boltzmann Machine model</a></p>
- <p><a href="#ref4">Setting the Model's Parameters</a></p>
- <p><a href="#ref1337">Recommendation</a></p>
<p></p>
</div>
<br>

----------

<a id="ref1"></a>
# Acquiring the Data

To start, we need to download the data we are going to use for our system. The datasets we're going to use were acquired by [GroupLens](http://grouplens.org/datasets/movielens/) and contain movies, users and movie ratings by these users.

After the download is done, we extract the datasets to a directory that's easily accessible.


```python
!wget -O moviedataset.zip http://files.grouplens.org/datasets/movielens/ml-1m.zip
!unzip -o moviedataset.zip -d /resources/data
```

    --2018-02-28 20:14:19--  http://files.grouplens.org/datasets/movielens/ml-1m.zip
    Resolving files.grouplens.org (files.grouplens.org)... 128.101.34.235
    Connecting to files.grouplens.org (files.grouplens.org)|128.101.34.235|:80... connected.
    HTTP request sent, awaiting response... 200 OK
    Length: 5917549 (5.6M) [application/zip]
    Saving to: ‘moviedataset.zip’
    
    moviedataset.zip    100%[===================>]   5.64M  18.4MB/s    in 0.3s    
    
    2018-02-28 20:14:19 (18.4 MB/s) - ‘moviedataset.zip’ saved [5917549/5917549]
    
    Archive:  moviedataset.zip
       creating: /resources/data/ml-1m/
      inflating: /resources/data/ml-1m/movies.dat  
      inflating: /resources/data/ml-1m/ratings.dat  
      inflating: /resources/data/ml-1m/README  
      inflating: /resources/data/ml-1m/users.dat  


With the datasets in place, let's now import the necessary libraries. We will be using [Tensorflow](https://www.tensorflow.org/) and [Numpy](http://www.numpy.org/) together to model and initialize our Restricted Boltzmann Machine and [Pandas](http://pandas.pydata.org/pandas-docs/stable/) to manipulate our datasets. To import these libraries, run the code cell below.


```python
#Tensorflow library. Used to implement machine learning models
import tensorflow as tf
#Numpy contains helpful functions for efficient mathematical calculations
import numpy as np
#Dataframe manipulation library
import pandas as pd
#Graph plotting library
import matplotlib.pyplot as plt
%matplotlib inline
```

-------------

<a id="ref2"></a>
# Loading in the Data

Let's begin by loading in our data with Pandas. The .dat files containing our data are similar to CSV files, but instead of using the ',' (comma) character to separate entries, it uses '::' (two colons) characters instead. To let Pandas know that it should separate data points at every '::', we have to specify the `sep='::'` parameter when calling the function.

Additionally, we also pass it the `header=None` parameter due to the fact that our files don't contain any headers.

Let's start with the movies.dat file and take a look at its structure:


```python
#Loading in the movies dataset
movies_df = pd.read_csv('/resources/data/ml-1m/movies.dat', sep='::', header=None)
movies_df.head()
```

    /usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.
      from ipykernel import kernelapp as app





<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>Toy Story (1995)</td>
      <td>Animation|Children's|Comedy</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>Jumanji (1995)</td>
      <td>Adventure|Children's|Fantasy</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>Grumpier Old Men (1995)</td>
      <td>Comedy|Romance</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>Waiting to Exhale (1995)</td>
      <td>Comedy|Drama</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>Father of the Bride Part II (1995)</td>
      <td>Comedy</td>
    </tr>
  </tbody>
</table>
</div>



We can do the same for the ratings.dat file:


```python
#Loading in the ratings dataset
ratings_df = pd.read_csv('/resources/data/ml-1m/ratings.dat', sep='::', header=None)
ratings_df.head()
```

    /usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.
      from ipykernel import kernelapp as app





<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1193</td>
      <td>5</td>
      <td>978300760</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>661</td>
      <td>3</td>
      <td>978302109</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>914</td>
      <td>3</td>
      <td>978301968</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>3408</td>
      <td>4</td>
      <td>978300275</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>2355</td>
      <td>5</td>
      <td>978824291</td>
    </tr>
  </tbody>
</table>
</div>



So our movies_df variable contains a dataframe that stores a movie's unique ID number, title and genres, while our ratings_df variable stores a unique User ID number, a movie's ID that the user has watched, the user's rating to said movie and when the user rated that movie.

Let's now rename the columns in these dataframes so we can better convey their data more intuitively:


```python
movies_df.columns = ['MovieID', 'Title', 'Genres']
ratings_df.columns = ['UserID', 'MovieID', 'Rating', 'Timestamp']
```

Here's our final movies_df:


```python
movies_df.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>MovieID</th>
      <th>Title</th>
      <th>Genres</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>Toy Story (1995)</td>
      <td>Animation|Children's|Comedy</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>Jumanji (1995)</td>
      <td>Adventure|Children's|Fantasy</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>Grumpier Old Men (1995)</td>
      <td>Comedy|Romance</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>Waiting to Exhale (1995)</td>
      <td>Comedy|Drama</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>Father of the Bride Part II (1995)</td>
      <td>Comedy</td>
    </tr>
  </tbody>
</table>
</div>



And our final ratings_df:


```python
ratings_df.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>UserID</th>
      <th>MovieID</th>
      <th>Rating</th>
      <th>Timestamp</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1193</td>
      <td>5</td>
      <td>978300760</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>661</td>
      <td>3</td>
      <td>978302109</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>914</td>
      <td>3</td>
      <td>978301968</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>3408</td>
      <td>4</td>
      <td>978300275</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>2355</td>
      <td>5</td>
      <td>978824291</td>
    </tr>
  </tbody>
</table>
</div>



-----------

<a id="ref3"></a>
# The Restricted Boltzmann Machine model

<img src="https://ibm.box.com/shared/static/o049tx0dsllpbj3b546vuba25qqlzelq.png" alt="RBM Model" style="width: 300px;"/>

The Restricted Boltzmann Machine model has two layers of neurons, one of which is what we call a visible input layer and the other is called a hidden layer. The hidden layer is used to learn features from the information fed through the input layer. For our model, the input is going to contain X neurons, where X is the amount of movies in our dataset. Each of these neurons will possess a normalized rating value varying from 0 to 1 -- 0 meaning that a user has not watched that movie and the closer the value is to 1, the more the user likes the movie that neuron's representing. These normalized values, of course, will be extracted and normalized from the ratings dataset.

After passing in the input, we train the RBM on it and have the hidden layer learn its features. These features are what we use to reconstruct the input, which in our case, will predict the ratings for movies that the input hasn't watched, which is exactly what we can use to recommend movies!

We will now begin to format our dataset to follow the model's expected input.

## Formatting the Data

First let's see how many movies we have and see if the movie ID's correspond with that value:


```python
len(movies_df)
```




    3883




```python
movies_df.tail()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>MovieID</th>
      <th>Title</th>
      <th>Genres</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>3878</th>
      <td>3948</td>
      <td>Meet the Parents (2000)</td>
      <td>Comedy</td>
    </tr>
    <tr>
      <th>3879</th>
      <td>3949</td>
      <td>Requiem for a Dream (2000)</td>
      <td>Drama</td>
    </tr>
    <tr>
      <th>3880</th>
      <td>3950</td>
      <td>Tigerland (2000)</td>
      <td>Drama</td>
    </tr>
    <tr>
      <th>3881</th>
      <td>3951</td>
      <td>Two Family House (2000)</td>
      <td>Drama</td>
    </tr>
    <tr>
      <th>3882</th>
      <td>3952</td>
      <td>Contender, The (2000)</td>
      <td>Drama|Thriller</td>
    </tr>
  </tbody>
</table>
</div>



As it is possible to notice, we have 3883 movies, while our ID's vary from 1 to 3952. Due to this, we won't be able to index movies through their ID since we would get memory indexing errors. To amend this, we can create a column that shows what spot in our list that particular movie is in:


```python
movies_df['List Index'] = movies_df.index
movies_df.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>MovieID</th>
      <th>Title</th>
      <th>Genres</th>
      <th>List Index</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>Toy Story (1995)</td>
      <td>Animation|Children's|Comedy</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>Jumanji (1995)</td>
      <td>Adventure|Children's|Fantasy</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>Grumpier Old Men (1995)</td>
      <td>Comedy|Romance</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>Waiting to Exhale (1995)</td>
      <td>Comedy|Drama</td>
      <td>3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>Father of the Bride Part II (1995)</td>
      <td>Comedy</td>
      <td>4</td>
    </tr>
  </tbody>
</table>
</div>



With that, let's merge the ratings dataframe into the movies one so we can have the List Index values in both dataframes. Additionally we're also going to drop the Timestamp, Title and Genres columns since we won't be needing it to make recommendations.


```python
#Merging movies_df with ratings_df by MovieID
merged_df = movies_df.merge(ratings_df, on='MovieID')
#Dropping unecessary columns
merged_df = merged_df.drop('Timestamp', axis=1).drop('Title', axis=1).drop('Genres', axis=1)
#Displaying the result
merged_df.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>MovieID</th>
      <th>List Index</th>
      <th>UserID</th>
      <th>Rating</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>5</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>0</td>
      <td>6</td>
      <td>4</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>0</td>
      <td>8</td>
      <td>4</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>0</td>
      <td>9</td>
      <td>5</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>0</td>
      <td>10</td>
      <td>5</td>
    </tr>
  </tbody>
</table>
</div>



Let's also group up the users by their user IDs and take a look at one of them.


```python
#Group up by UserID
userGroup = merged_df.groupby('UserID')
userGroup.first().head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>MovieID</th>
      <th>List Index</th>
      <th>Rating</th>
    </tr>
    <tr>
      <th>UserID</th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>0</td>
      <td>5</td>
    </tr>
    <tr>
      <th>2</th>
      <td>21</td>
      <td>20</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>104</td>
      <td>102</td>
      <td>4</td>
    </tr>
    <tr>
      <th>4</th>
      <td>260</td>
      <td>257</td>
      <td>5</td>
    </tr>
    <tr>
      <th>5</th>
      <td>6</td>
      <td>5</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
</div>



Now, we can start formatting the data into input for the RBM. We're going to store the normalized users ratings into a list of lists called trX.


```python
#Amount of users used for training
amountOfUsedUsers = 1000
#Creating the training list
trX = []
#For each user in the group
for userID, curUser in userGroup:
    #Create a temp that stores every movie's rating
    temp = [0]*len(movies_df)
    #For each movie in curUser's movie list
    for num, movie in curUser.iterrows():
        #Divide the rating by 5 and store it
        temp[movie['List Index']] = movie['Rating']/5.0
    #Now add the list of ratings into the training list
    trX.append(temp)
    #Check to see if we finished adding in the amount of users for training
    if amountOfUsedUsers == 0:
        break
    amountOfUsedUsers -= 1
```

------------

<a id="ref4"></a>
# Setting the Model's Parameters

Next, let's start building our RBM with Tensorflow. We'll begin by first determining the amount of hidden layers and then creating placeholder variables for storing our visible layer biases, hidden layer biases and weights that connect the hidden layer with the visible one. We will be arbitrarily setting the amount of hidden layers to 20. You can freely set this value to any number you want since each neuron in the hidden layer will end up learning a feature.


```python
hiddenUnits = 20
visibleUnits = len(movies_df)
vb = tf.placeholder("float", [visibleUnits]) #Number of unique movies
hb = tf.placeholder("float", [hiddenUnits]) #Number of features we're going to learn
W = tf.placeholder("float", [visibleUnits, hiddenUnits])
```

We then move on to creating the visible and hidden layer units and setting their activation functions. In this case, we will be using the `tf.sigmoid` and `tf.relu` functions as nonlinear activations since it's what is usually used in RBM's.


```python
#Phase 1: Input Processing
v0 = tf.placeholder("float", [None, visibleUnits])
_h0= tf.nn.sigmoid(tf.matmul(v0, W) + hb)
h0 = tf.nn.relu(tf.sign(_h0 - tf.random_uniform(tf.shape(_h0))))
#Phase 2: Reconstruction
_v1 = tf.nn.sigmoid(tf.matmul(h0, tf.transpose(W)) + vb) 
v1 = tf.nn.relu(tf.sign(_v1 - tf.random_uniform(tf.shape(_v1))))
h1 = tf.nn.sigmoid(tf.matmul(v1, W) + hb)
```

Now we set the RBM training parameters and functions.


```python
#Learning rate
alpha = 1.0
#Create the gradients
w_pos_grad = tf.matmul(tf.transpose(v0), h0)
w_neg_grad = tf.matmul(tf.transpose(v1), h1)
#Calculate the Contrastive Divergence to maximize
CD = (w_pos_grad - w_neg_grad) / tf.to_float(tf.shape(v0)[0])
#Create methods to update the weights and biases
update_w = W + alpha * CD
update_vb = vb + alpha * tf.reduce_mean(v0 - v1, 0)
update_hb = hb + alpha * tf.reduce_mean(h0 - h1, 0)
```

And set the error function, which in this case will be the Mean Absolute Error Function.


```python
err = v0 - v1
err_sum = tf.reduce_mean(err * err)
```

We also have to initialize our variables. Thankfully, NumPy has a handy `zeros` function for this. We use it like so:


```python
#Current weight
cur_w = np.zeros([visibleUnits, hiddenUnits], np.float32)
#Current visible unit biases
cur_vb = np.zeros([visibleUnits], np.float32)
#Current hidden unit biases
cur_hb = np.zeros([hiddenUnits], np.float32)
#Previous weight
prv_w = np.zeros([visibleUnits, hiddenUnits], np.float32)
#Previous visible unit biases
prv_vb = np.zeros([visibleUnits], np.float32)
#Previous hidden unit biases
prv_hb = np.zeros([hiddenUnits], np.float32)
sess = tf.Session()
sess.run(tf.global_variables_initializer())
```

Now we train the RBM with 15 epochs with each epoch using 10 batches with size 100. After training, we print out a graph with the error by epoch.


```python
epochs = 15
batchsize = 100
errors = []
for i in range(epochs):
    for start, end in zip( range(0, len(trX), batchsize), range(batchsize, len(trX), batchsize)):
        batch = trX[start:end]
        cur_w = sess.run(update_w, feed_dict={v0: batch, W: prv_w, vb: prv_vb, hb: prv_hb})
        cur_vb = sess.run(update_vb, feed_dict={v0: batch, W: prv_w, vb: prv_vb, hb: prv_hb})
        cur_nb = sess.run(update_hb, feed_dict={v0: batch, W: prv_w, vb: prv_vb, hb: prv_hb})
        prv_w = cur_w
        prv_vb = cur_vb
        prv_hb = cur_nb
    errors.append(sess.run(err_sum, feed_dict={v0: trX, W: cur_w, vb: cur_vb, hb: cur_nb}))
    print errors[-1]
plt.plot(errors)
plt.ylabel('Error')
plt.xlabel('Epoch')
plt.show()
```

    0.123721
    0.0827301
    0.0683777
    0.060279
    0.0529957
    0.0480692
    0.0453992
    0.0442634
    0.0434854
    0.0429502
    0.0420477
    0.0413439
    0.0408893
    0.0404992
    0.0402052



![png](output_48_1.png)


--------------

<a id="ref1337"></a>
## Recommendation

We can now predict movies that an arbitrarily selected user might like. This can be accomplished by feeding in the user's watched movie preferences into the RBM and then reconstructing the input. The values that the RBM gives us will attempt to estimate the user's preferences for movies that he hasn't watched based on the preferences of the users that the RBM was trained on.


```python
#Selecting the input user
inputUser = [trX[75]]
```


```python
#Feeding in the user and reconstructing the input
hh0 = tf.nn.sigmoid(tf.matmul(v0, W) + hb)
vv1 = tf.nn.sigmoid(tf.matmul(hh0, tf.transpose(W)) + vb)
feed = sess.run(hh0, feed_dict={ v0: inputUser, W: prv_w, hb: prv_hb})
rec = sess.run(vv1, feed_dict={ hh0: feed, W: prv_w, vb: prv_vb})
```

We can then list the 20 most recommended movies for our mock user by sorting it by their scores given by our model.


```python
scored_movies_df_75 = movies_df
scored_movies_df_75["Recommendation Score"] = rec[0]
scored_movies_df_75.sort(["Recommendation Score"], ascending=False).head(20)
```

    /usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:3: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)
      app.launch_new_instance()





<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>MovieID</th>
      <th>Title</th>
      <th>Genres</th>
      <th>List Index</th>
      <th>Recommendation Score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1959</th>
      <td>2028</td>
      <td>Saving Private Ryan (1998)</td>
      <td>Action|Drama|War</td>
      <td>1959</td>
      <td>0.747958</td>
    </tr>
    <tr>
      <th>589</th>
      <td>593</td>
      <td>Silence of the Lambs, The (1991)</td>
      <td>Drama|Thriller</td>
      <td>589</td>
      <td>0.676758</td>
    </tr>
    <tr>
      <th>315</th>
      <td>318</td>
      <td>Shawshank Redemption, The (1994)</td>
      <td>Drama</td>
      <td>315</td>
      <td>0.666809</td>
    </tr>
    <tr>
      <th>2789</th>
      <td>2858</td>
      <td>American Beauty (1999)</td>
      <td>Comedy|Drama</td>
      <td>2789</td>
      <td>0.663631</td>
    </tr>
    <tr>
      <th>604</th>
      <td>608</td>
      <td>Fargo (1996)</td>
      <td>Crime|Drama|Thriller</td>
      <td>604</td>
      <td>0.623226</td>
    </tr>
    <tr>
      <th>2693</th>
      <td>2762</td>
      <td>Sixth Sense, The (1999)</td>
      <td>Thriller</td>
      <td>2693</td>
      <td>0.597613</td>
    </tr>
    <tr>
      <th>523</th>
      <td>527</td>
      <td>Schindler's List (1993)</td>
      <td>Drama|War</td>
      <td>523</td>
      <td>0.585510</td>
    </tr>
    <tr>
      <th>293</th>
      <td>296</td>
      <td>Pulp Fiction (1994)</td>
      <td>Crime|Drama</td>
      <td>293</td>
      <td>0.582088</td>
    </tr>
    <tr>
      <th>2327</th>
      <td>2396</td>
      <td>Shakespeare in Love (1998)</td>
      <td>Comedy|Romance</td>
      <td>2327</td>
      <td>0.571933</td>
    </tr>
    <tr>
      <th>1575</th>
      <td>1617</td>
      <td>L.A. Confidential (1997)</td>
      <td>Crime|Film-Noir|Mystery|Thriller</td>
      <td>1575</td>
      <td>0.551928</td>
    </tr>
    <tr>
      <th>2928</th>
      <td>2997</td>
      <td>Being John Malkovich (1999)</td>
      <td>Comedy</td>
      <td>2928</td>
      <td>0.539781</td>
    </tr>
    <tr>
      <th>108</th>
      <td>110</td>
      <td>Braveheart (1995)</td>
      <td>Action|Drama|War</td>
      <td>108</td>
      <td>0.453142</td>
    </tr>
    <tr>
      <th>3045</th>
      <td>3114</td>
      <td>Toy Story 2 (1999)</td>
      <td>Animation|Children's|Comedy</td>
      <td>3045</td>
      <td>0.452197</td>
    </tr>
    <tr>
      <th>1195</th>
      <td>1213</td>
      <td>GoodFellas (1990)</td>
      <td>Crime|Drama</td>
      <td>1195</td>
      <td>0.440178</td>
    </tr>
    <tr>
      <th>257</th>
      <td>260</td>
      <td>Star Wars: Episode IV - A New Hope (1977)</td>
      <td>Action|Adventure|Fantasy|Sci-Fi</td>
      <td>257</td>
      <td>0.427864</td>
    </tr>
    <tr>
      <th>1245</th>
      <td>1265</td>
      <td>Groundhog Day (1993)</td>
      <td>Comedy|Romance</td>
      <td>1245</td>
      <td>0.424206</td>
    </tr>
    <tr>
      <th>49</th>
      <td>50</td>
      <td>Usual Suspects, The (1995)</td>
      <td>Crime|Thriller</td>
      <td>49</td>
      <td>0.417062</td>
    </tr>
    <tr>
      <th>3509</th>
      <td>3578</td>
      <td>Gladiator (2000)</td>
      <td>Action|Drama</td>
      <td>3509</td>
      <td>0.416149</td>
    </tr>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>Toy Story (1995)</td>
      <td>Animation|Children's|Comedy</td>
      <td>0</td>
      <td>0.406608</td>
    </tr>
    <tr>
      <th>2502</th>
      <td>2571</td>
      <td>Matrix, The (1999)</td>
      <td>Action|Sci-Fi|Thriller</td>
      <td>2502</td>
      <td>0.385308</td>
    </tr>
  </tbody>
</table>
</div>



So, how to recommend the movies that the user has not watched yet? 

Lets first find the __User ID__ of our mock user:


```python
merged_df.iloc[75]
```




    MovieID         1
    List Index      0
    UserID        215
    Rating          4
    Name: 75, dtype: int64



Now, we can find all the movies that our mock user has watched before:


```python
movies_df_75 = merged_df[merged_df['UserID']==215]
movies_df_75.head()
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>MovieID</th>
      <th>List Index</th>
      <th>UserID</th>
      <th>Rating</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>75</th>
      <td>1</td>
      <td>0</td>
      <td>215</td>
      <td>4</td>
    </tr>
    <tr>
      <th>11873</th>
      <td>24</td>
      <td>23</td>
      <td>215</td>
      <td>5</td>
    </tr>
    <tr>
      <th>67543</th>
      <td>260</td>
      <td>257</td>
      <td>215</td>
      <td>5</td>
    </tr>
    <tr>
      <th>82782</th>
      <td>316</td>
      <td>313</td>
      <td>215</td>
      <td>4</td>
    </tr>
    <tr>
      <th>97063</th>
      <td>356</td>
      <td>352</td>
      <td>215</td>
      <td>5</td>
    </tr>
  </tbody>
</table>
</div>



In the next cell, we merge all the movies that our mock users has watched with the predicted scors based on his historical data:


```python
#Merging movies_df with ratings_df by MovieID
merged_df_75 = scored_movies_df_75.merge(movies_df_75, on='MovieID', how='outer')
#Dropping unecessary columns
merged_df_75 = merged_df_75.drop('List Index_y', axis=1).drop('UserID', axis=1)
```

lets sort it and take a look at the firt 20 rows:


```python
merged_df_75.sort(["Recommendation Score"], ascending=False).head(20)
```

    /usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:1: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)
      if __name__ == '__main__':





<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>MovieID</th>
      <th>Title</th>
      <th>Genres</th>
      <th>List Index_x</th>
      <th>Recommendation Score</th>
      <th>Rating</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1959</th>
      <td>2028</td>
      <td>Saving Private Ryan (1998)</td>
      <td>Action|Drama|War</td>
      <td>1959</td>
      <td>0.747958</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>589</th>
      <td>593</td>
      <td>Silence of the Lambs, The (1991)</td>
      <td>Drama|Thriller</td>
      <td>589</td>
      <td>0.676758</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>315</th>
      <td>318</td>
      <td>Shawshank Redemption, The (1994)</td>
      <td>Drama</td>
      <td>315</td>
      <td>0.666809</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2789</th>
      <td>2858</td>
      <td>American Beauty (1999)</td>
      <td>Comedy|Drama</td>
      <td>2789</td>
      <td>0.663631</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>604</th>
      <td>608</td>
      <td>Fargo (1996)</td>
      <td>Crime|Drama|Thriller</td>
      <td>604</td>
      <td>0.623226</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2693</th>
      <td>2762</td>
      <td>Sixth Sense, The (1999)</td>
      <td>Thriller</td>
      <td>2693</td>
      <td>0.597613</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>523</th>
      <td>527</td>
      <td>Schindler's List (1993)</td>
      <td>Drama|War</td>
      <td>523</td>
      <td>0.585510</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>293</th>
      <td>296</td>
      <td>Pulp Fiction (1994)</td>
      <td>Crime|Drama</td>
      <td>293</td>
      <td>0.582088</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2327</th>
      <td>2396</td>
      <td>Shakespeare in Love (1998)</td>
      <td>Comedy|Romance</td>
      <td>2327</td>
      <td>0.571933</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1575</th>
      <td>1617</td>
      <td>L.A. Confidential (1997)</td>
      <td>Crime|Film-Noir|Mystery|Thriller</td>
      <td>1575</td>
      <td>0.551928</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>2928</th>
      <td>2997</td>
      <td>Being John Malkovich (1999)</td>
      <td>Comedy</td>
      <td>2928</td>
      <td>0.539781</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>108</th>
      <td>110</td>
      <td>Braveheart (1995)</td>
      <td>Action|Drama|War</td>
      <td>108</td>
      <td>0.453142</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>3045</th>
      <td>3114</td>
      <td>Toy Story 2 (1999)</td>
      <td>Animation|Children's|Comedy</td>
      <td>3045</td>
      <td>0.452197</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1195</th>
      <td>1213</td>
      <td>GoodFellas (1990)</td>
      <td>Crime|Drama</td>
      <td>1195</td>
      <td>0.440178</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>257</th>
      <td>260</td>
      <td>Star Wars: Episode IV - A New Hope (1977)</td>
      <td>Action|Adventure|Fantasy|Sci-Fi</td>
      <td>257</td>
      <td>0.427864</td>
      <td>5.0</td>
    </tr>
    <tr>
      <th>1245</th>
      <td>1265</td>
      <td>Groundhog Day (1993)</td>
      <td>Comedy|Romance</td>
      <td>1245</td>
      <td>0.424206</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>49</th>
      <td>50</td>
      <td>Usual Suspects, The (1995)</td>
      <td>Crime|Thriller</td>
      <td>49</td>
      <td>0.417062</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>3509</th>
      <td>3578</td>
      <td>Gladiator (2000)</td>
      <td>Action|Drama</td>
      <td>3509</td>
      <td>0.416149</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>Toy Story (1995)</td>
      <td>Animation|Children's|Comedy</td>
      <td>0</td>
      <td>0.406608</td>
      <td>4.0</td>
    </tr>
    <tr>
      <th>2502</th>
      <td>2571</td>
      <td>Matrix, The (1999)</td>
      <td>Action|Sci-Fi|Thriller</td>
      <td>2502</td>
      <td>0.385308</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>



As you can see, there are some movies that user has not watched yet and has high score based on our model. So, we can recommend them to user.

This is the end of the module. If you want, you can try to change the parameters in the code -- adding more units to the hidden layer, changing the loss functions or maybe something else to see if it changes anything. Does the model perform better? Does it take longer to compute?

Thank you for reading this notebook. Hopefully, you now have a little more understanding of the RBM model, its applications and how it works with TensorFlow.

## Want to learn more?

Running deep learning programs usually needs a high performance platform. PowerAI speeds up deep learning and AI. Built on IBM's Power Systems, PowerAI is a scalable software platform that accelerates deep learning and AI with blazing performance for individual users or enterprises. The PowerAI platform supports popular machine learning libraries and dependencies including Tensorflow, Caffe, Torch, and Theano. You can download a [free version of PowerAI](https://cocl.us/ML0120EN_PAI).

Also, you can use Data Science Experience to run these notebooks faster with bigger datasets. Data Science Experience is IBM's leading cloud solution for data scientists, built by data scientists. With Jupyter notebooks, RStudio, Apache Spark and popular libraries pre-packaged in the cloud, DSX enables data scientists to collaborate on their projects without having to install anything. Join the fast-growing community of DSX users today with a free account at [Data Science Experience](https://cocl.us/ML0120EN_DSX)This is the end of this lesson. Hopefully, now you have a deeper and intuitive understanding regarding the LSTM model. Thank you for reading this notebook, and good luck on your studies.

### Thank you for completing this exercise!

Notebook created by: Gabriel Garcez Barros Sousa, <a href = "https://ca.linkedin.com/in/saeedaghabozorgi">Saeed Aghabozorgi</a>, <a href = "https://www.linkedin.com/in/franciscomagioli">Francisco Magioli</a>

## References
* [Restricted Boltzmann Machines for Collaborative Filtering](http://www.cs.utoronto.ca/~hinton/absps/netflixICML.pdf)
* <font='red'>RBM Notebook</font>

<hr>
Copyright &copy; 2017 [IBM Cognitive Class](https://cocl.us/ML0120EN_cclab_cc). This notebook and its source code are released under the terms of the [MIT License](https://cognitiveclass.ai/mit-license/).


```python

```
